{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9597802c",
   "metadata": {},
   "source": [
    "# Runhouse\n",
    "\n",
    "The [Runhouse](https://www.run.house/) allows remote compute and data across environments and users. See the [Runhouse docs](https://www.run.house/docs).\n",
    "\n",
    "This example goes over how to use LangChain and [Runhouse](https://github.com/run-house/runhouse) to interact with models hosted on your own GPU, or on-demand GPUs on AWS, GCP, AWS, or Lambda.\n",
    "\n",
    "**Note**: Code uses `SelfHosted` name instead of the `Runhouse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066fede-2300-4173-9722-6f01f4fa34b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet \"runhouse[sky]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb585dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import runhouse as rh\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import SelfHostedHuggingFaceLLM, SelfHostedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d6866e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<runhouse.resources.hardware.on_demand_cluster.OnDemandCluster at 0x107573fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For an on-demand A100 with GCP, Azure, or Lambda\n",
    "gpu = rh.cluster(name=\"langchain-rh-a10x\", instance_type=\"g5.4xlarge\")\n",
    "gpu.up_if_not()\n",
    "# For an on-demand A10G with AWS (no single A100s on AWS)\n",
    "# gpu = rh.cluster(name='rh-a10x', instance_type='g5.2xlarge', provider='aws')\n",
    "\n",
    "# For an existing cluster\n",
    "# gpu = rh.cluster(ips=['<ip of the cluster>'],\n",
    "#                  ssh_creds={'ssh_user': '...', 'ssh_private_key':'<path_to_key>'},\n",
    "#                  name='rh-a10x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7dcb5-7a74-4513-9ad6-aee1b4193b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_env = rh.env(\n",
    "    name=\"model_env\",\n",
    "    reqs=[\"transformers\", \"torch\", \"accelerate\", \"huggingface-hub\"],\n",
    "    secrets=[\"huggingface\"],  # need for downloading google/gemma-2b-it\n",
    ").to(system=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628d8b2-ec20-49d6-9782-2dcd64640328",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu.run(commands=[\"pip install langchain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228abaf-0eb3-4828-a153-640d60790ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = SelfHostedHuggingFaceLLM(\n",
    "    model_id=\"google/gemma-2b-it\",\n",
    "    hardware=gpu,\n",
    "    env=model_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035dea0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b4f06a-c698-4e69-9fee-f2efbe35976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a641dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb6fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sashabelousovrh/PycharmProjects/LangchainIntegration/langchain/libs/core/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "INFO | 2024-03-24 12:43:27.185705 | Calling LangchainLLMModelPipeline.interface_fn\n",
      "INFO | 2024-03-24 12:45:19.638441 | Time to call LangchainLLMModelPipeline.interface_fn: 112.45 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe word \"Germany\" has numerous meanings and can refer to different countries around the world.\\n\\nThe capital city of Germany is Berlin, which is located in the center of the country.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the capital of Germany?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3729af-ebe2-4fd9-baa8-eb9e28f1122b",
   "metadata": {},
   "source": [
    "You can also execute the prediction function of the model directly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1528e70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sashabelousovrh/PycharmProjects/LangchainIntegration/langchain/libs/core/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "INFO | 2024-03-24 12:45:29.004133 | Calling LangchainLLMModelPipeline.interface_fn\n",
      "INFO | 2024-03-24 12:47:46.580013 | Time to call LangchainLLMModelPipeline.interface_fn: 137.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sunday. \\n\\nThe crowd roars loud, the lights ignite,\\nA symphony of cheers resound in the night.\\nThe players take the field, the tension grows,\\nFor victory or defeat, the battle flows.\\n\\nThe atmosphere is electric and alive,\\nA spectacle of passion and strife.\\nThe atmosphere'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Write me a short poem about Super Bowl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a652034-d090-47ad-ae3d-6b8796248eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
